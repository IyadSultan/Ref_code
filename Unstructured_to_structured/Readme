Structured Data Extraction with Pydantic, OpenAI and LangChain
Extracting structured data from raw, unstructured text can be a challenging task, especially when dealing with large volumes of data. This project combines the powerful data validation library Pydantic, OpenAI's language model function calling, and LangChain's AI models to efficiently parse text data and extract relevant information in a structured format.

Scenario
Suppose you have numerous blog posts and articles about healthcare startups, and you want to extract key information from this text into a structured format for further analysis. This project provides an easy and efficient way to accomplish this.

How does it work?
Here's a high-level overview:

Define the desired structured data format: We use Pydantic to define classes that represent the structured data we want to extract from the text. This involves creating classes for each relevant entity (such as Founders and Startups) and defining the attributes we want to capture for each entity.

Initialize a chat model: Using LangChain, we initialize an OpenAI chat model.

Create a function for data extraction: We convert our Pydantic model into a function and pass it, along with the original text, to the chat model.

Extract the data: The model processes the text and returns the extracted data in the structured format defined by our Pydantic models.

Example Code
Here's a sample implementation of the process described above:

python
Copy code
# Import the required libraries and modules
from typing import Optional, List
from pydantic import BaseModel, Field
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
import json

from dotenv import load_dotenv
load_dotenv() 

# Define the query text
text = """
...
"""

# Define Pydantic models
class Founder(BaseModel):
    ...
class Startup(BaseModel):
    ...
class Startups(BaseModel):
    ...

# Prepare the query
query = HumanMessage(content=text)

# Initialize the ChatOpenAI instance
llm = ChatOpenAI()

# Define the functions
functions = [
    {"name": "get_startup_info", "description": "extract startup name and basic info from text", "parameters": Startups.schema()}
]

# Perform the function call
response = llm([query], functions=functions, function_call="auto")

# Extract the function call arguments from the response
result = response.additional_kwargs['function_call']['arguments']

# Load the result as JSON
data = json.loads(result)

# Print extracted data
for startup in data['startups']:
    ...
This simple yet powerful process allows you to parse the output data and use it for your analysis, display it in a readable format, save it for later use, and more.

Requirements
Pydantic
LangChain
OpenAI
python-dotenv
For the detailed code and instructions, check out the main code file in this repository.

Start extracting structured data from unstructured text in an efficient and easy way!